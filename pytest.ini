[pytest]
# Pytest configuration for PM Document Intelligence

# Test discovery patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = tests

# Minimum Python version
minversion = 3.11

# Add current directory to Python path
pythonpath = .

# Markers for categorizing tests
markers =
    unit: Unit tests (fast, isolated, no external dependencies)
    integration: Integration tests (may use database, external services)
    e2e: End-to-end tests using Playwright (slow, full stack)
    slow: Slow-running tests (may take > 5 seconds)
    aws: Tests requiring AWS services (can be mocked or use LocalStack)
    database: Tests requiring database access
    visual: Visual regression tests with screenshot comparison
    security: Security and penetration testing
    smoke: Smoke tests for quick validation

# Coverage configuration
[coverage:run]
source = app
omit =
    */tests/*
    */venv/*
    */__pycache__/*
    */migrations/*
    */config.py

[coverage:report]
precision = 2
show_missing = True
skip_covered = False
fail_under = 80

exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstractmethod
    @abc.abstractmethod

# Coverage HTML report
[coverage:html]
directory = htmlcov

# Console output options
console_output_style = progress
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# File logging
log_file = pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Warnings configuration
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Asyncio mode
asyncio_mode = auto

# Parallel execution
addopts =
    -v
    --strict-markers
    --tb=short
    --cov=app
    --cov-report=term-missing
    --cov-report=html
    --cov-report=xml
    --maxfail=10
    --disable-warnings
    -p no:warnings
    --durations=10

# Timeout for tests (seconds)
timeout = 300

# Doctest
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL

# ============================================================================
# Running different test suites
# ============================================================================

# Run only unit tests:
#   pytest -m unit

# Run only integration tests:
#   pytest -m integration

# Run unit and integration tests:
#   pytest -m "unit or integration"

# Run all tests except slow ones:
#   pytest -m "not slow"

# Run all tests except e2e:
#   pytest -m "not e2e"

# Run with parallel execution (requires pytest-xdist):
#   pytest -n auto

# Run with coverage:
#   pytest --cov=app --cov-report=html

# Run specific test file:
#   pytest tests/unit/test_auth.py

# Run specific test class:
#   pytest tests/unit/test_auth.py::TestPasswordHashing

# Run specific test:
#   pytest tests/unit/test_auth.py::TestPasswordHashing::test_hash_password

# Run tests matching pattern:
#   pytest -k "test_login"

# Run with verbose output:
#   pytest -vv

# Stop after first failure:
#   pytest -x

# Run failed tests from last run:
#   pytest --lf

# Run in parallel (4 workers):
#   pytest -n 4

# Generate JUnit XML report:
#   pytest --junitxml=junit.xml

# Generate HTML report (requires pytest-html):
#   pytest --html=report.html

# ============================================================================
# CI/CD Configuration
# ============================================================================

# For CI, you might want to:
# 1. Skip slow tests: pytest -m "not slow and not e2e"
# 2. Run with strict coverage: pytest --cov=app --cov-fail-under=80
# 3. Generate reports: pytest --junitxml=junit.xml --cov-report=xml

# Example CI command:
#   pytest -m "not e2e" --cov=app --cov-report=xml --junitxml=junit.xml --maxfail=5
